{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Digit Classification with Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will use simple logistic regression to see how far we can get when classifying images with digits on it. For this we use the famous MNIST dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data Loading and Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We work with the MNIST dataset which is a large database of handwritten digits and very popular for testing machine learning models. You can find more details about the dataset [here](https://en.wikipedia.org/wiki/MNIST_database).\n",
    "\n",
    "We download the dataset directly via the sklearn library. This may take a short while ... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "x, y = fetch_openml('mnist_784', version=1, return_X_y=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we have a brief look at the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X is a <class 'pandas.core.frame.DataFrame'>\n",
      "y is a <class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "print(\"X is a\", type(x))\n",
    "print(\"y is a\", type(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 784)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>pixel10</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  pixel9  \\\n",
       "0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "1     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "2     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "   pixel10  ...  pixel775  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n",
       "0      0.0  ...       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "1      0.0  ...       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "2      0.0  ...       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "\n",
       "   pixel781  pixel782  pixel783  pixel784  \n",
       "0       0.0       0.0       0.0       0.0  \n",
       "1       0.0       0.0       0.0       0.0  \n",
       "2       0.0       0.0       0.0       0.0  \n",
       "\n",
       "[3 rows x 784 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One data point consists of 784 pixel values (=28x28 pixels) that represent an image showing a handwritten digit.\n",
    "Let's look at the data for one data point:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    784.000000\n",
       "mean      35.108418\n",
       "std       79.699674\n",
       "min        0.000000\n",
       "25%        0.000000\n",
       "50%        0.000000\n",
       "75%        0.000000\n",
       "max      255.000000\n",
       "Name: 0, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.iloc[0].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pixels of one datapoint have values between 0 and 255 which correspond to the grey value of that pixel. A value of zero means that the pixel is black, a value of 255 corresponds to a white pixel, every other value is some grey value in between."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The labels of the data are the digits that are actually shown on the image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    5\n",
       "1    0\n",
       "2    4\n",
       "Name: class, dtype: category\n",
       "Categories (10, object): ['0', '1', '2', '3', ..., '6', '7', '8', '9']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y.iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the label is of type string, we convert it to an integer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.astype(\"int\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get an impression how the pictures of the digits look like, we visualize the first three rows with matplotlib. For this, we need to reshape each row to dimension 28x28 and then plot it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.5, 27.5, 27.5, -0.5)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "digit = x.iloc[0]\n",
    "digit_pixels = np.array(digit).reshape(28, 28)\n",
    "plt.subplot(131)\n",
    "plt.title(\"Label \" + str(y.iloc[0]))\n",
    "plt.imshow(digit_pixels, cmap=plt.cm.gray)\n",
    "plt.axis('off')\n",
    "\n",
    "digit = x.iloc[1]\n",
    "digit_pixels = np.array(digit).reshape(28, 28)\n",
    "plt.subplot(132)\n",
    "plt.title(\"Label \" + str(y.iloc[1]))\n",
    "plt.imshow(digit_pixels, cmap=plt.cm.gray)\n",
    "plt.axis('off')\n",
    "\n",
    "digit = x.iloc[2]\n",
    "digit_pixels = np.array(digit).reshape(28, 28)\n",
    "plt.subplot(133)\n",
    "plt.title(\"Label \" + str(y.iloc[2]))\n",
    "plt.imshow(digit_pixels, cmap=plt.cm.gray)\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we start with the model training we divide it into train and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data points: 56000\n",
      "Test data points: 14000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)\n",
    "\n",
    "print(\"Train data points:\", len(X_train))\n",
    "print(\"Test data points:\", len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first step we normalize the data with min-max normaliziation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = (X_train/255).astype('float32').values # min-max-normalize\n",
    "X_test = (X_test/255).astype('float32').values # min-max-normalize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this is a multiclass classficiation problem, we will use an one-vs-rest approch for logisitc regession, which means that we train an individual model for each digit.\n",
    "\n",
    "In order to do that, we need for each model an individual representation of the label, in which only the digit on which the model is trained on is `1` on the rest is zero. For this we impelement the following function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_to_binary(digit, labels):\n",
    "    binary_labels = []\n",
    "    for label in labels:\n",
    "        if(label == digit):\n",
    "            binary_labels.append(1)\n",
    "        else:\n",
    "            binary_labels.append(0)\n",
    "    return np.array(binary_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test this, we train a model that only predicts if there is a \"9\" on the image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old labels: [4 9 6 7 5 1 9 6 7 9]\n",
      "New labels: [0 1 0 0 0 0 1 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "y_train_9 = label_to_binary(9, y_train)\n",
    "y_test_9 = label_to_binary(9, y_test)\n",
    "\n",
    "print(\"Old labels:\", y_train[:10].values)\n",
    "print(\"New labels:\", y_train_9[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=1000)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logisticRegr = LogisticRegression(max_iter=1000) # Gradient Descent with max. 1000 steps\n",
    "logisticRegr.fit(X_train, y_train_9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.966"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "predictions = logisticRegr.predict(X_test)\n",
    "accuracy_score(y_test_9, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We next train a model for every digit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "for i in range(0, 10):\n",
    "    logisticRegr = LogisticRegression(max_iter=1000)\n",
    "    y_train_binary = label_to_binary(i, y_train)\n",
    "    logisticRegr.fit(X_train, y_train_binary)\n",
    "    models.append(logisticRegr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Model Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For testing, we now predict with every model on a test data point and use the model which has the highest probabilty as prediction result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = []\n",
    "for data_point in X_test:\n",
    "    predictions = []\n",
    "    for model in models:  \n",
    "        prediction = model.predict_proba([data_point])[0][1]\n",
    "        predictions.append(prediction)\n",
    "    predicted_class = predictions.index(max(predictions))\n",
    "    test_predictions.append(predicted_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9098571428571428"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, test_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do the same as above but try out different lambdas for the regulariuzation.\n",
    "Note: We only train one `LogisticRegression` object in this case, because the `LogisticRegression` class does the \"one-vs-rest\" by default when confronted with more than two classes :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=LogisticRegression(max_iter=1000), n_jobs=-1,\n",
       "             param_grid=[{'C': [0.1, 1.0, 10.0]}])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameter_candidates = [{'C': [0.1, 1.0, 10.0]}]\n",
    "\n",
    "logisticRegr = LogisticRegression(max_iter=1000)\n",
    "grid_lr = GridSearchCV(estimator=logisticRegr, param_grid=parameter_candidates, n_jobs=-1)\n",
    "grid_lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9187142857142857"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/dmml2/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/miniconda3/envs/dmml2/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/miniconda3/envs/dmml2/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/miniconda3/envs/dmml2/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/miniconda3/envs/dmml2/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "predictions = grid_lr.predict(X_test)\n",
    "accuracy_score(y_test, predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

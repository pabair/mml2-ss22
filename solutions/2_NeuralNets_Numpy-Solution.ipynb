{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Neural Networks with Numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will build our first neural network using only `numpy` as library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will work on the same dataset as last week and try to predict which digit is shown on the given pixel values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "X, y = fetch_openml('mnist_784', version=1, return_X_y=True, data_home=\"./data\", cache=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know already from last time how the data looks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>pixel10</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  pixel9  \\\n",
       "0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "1     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "2     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "   pixel10  ...  pixel775  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n",
       "0      0.0  ...       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "1      0.0  ...       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "2      0.0  ...       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "\n",
       "   pixel781  pixel782  pixel783  pixel784  \n",
       "0       0.0       0.0       0.0       0.0  \n",
       "1       0.0       0.0       0.0       0.0  \n",
       "2       0.0       0.0       0.0       0.0  \n",
       "\n",
       "[3 rows x 784 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The label is a number between 0-9 representing the digit shown on the pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    5\n",
       "1    0\n",
       "2    4\n",
       "Name: class, dtype: category\n",
       "Categories (10, object): ['0', '1', '2', '3', ..., '6', '7', '8', '9']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from above, the label is given as a digit. However, to calculate the loss function of the neural network, we need the label as a one-hot-encoded version, in which the label is encoded as `1` and the rest as `0`.\n",
    "\n",
    "For instance:\n",
    "- `3` -> `[0, 0, 0, 1, 0, 0, 0, 0, 0, 0]`\n",
    "- `9` -> `[0, 0, 0, 0, 0, 0, 0, 0, 0, 1]`\n",
    "\n",
    "This is done in the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "y_categorical = pd.get_dummies(y).astype('float32').values\n",
    "y_categorical[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we start, we scale the data and divide it into train and test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_scaled = (X/255).astype('float32').values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_categorical, test_size=0.15, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Implement the Forward pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start with the following structure of a neural network with two hidden layers:\n",
    "- Input layer of size 784 with sigmoid activation\n",
    "- First hidden layer of size 128 with sigmoid activation\n",
    "- Second hidden layer of size 64 with sigmoid activation\n",
    "- Output layer of size 10 with softmax activation\n",
    "\n",
    "A skeleton code for this network is given in the following class. Your first task is to complete the method `forward_pass` to calculate the forward pass on one data point. After this class you can find a test to check whether your implementation is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "\n",
    "class DeepNeuralNetwork():\n",
    "    def __init__(self):\n",
    "        \n",
    "        # initialize weights randomly\n",
    "        np.random.seed(0)\n",
    "        self.w1 = np.random.randn(128, 784)\n",
    "        self.w2 = np.random.randn(64, 128)\n",
    "        self.w3 = np.random.randn(10, 64)\n",
    "\n",
    "    def forward_pass(self, x_train):\n",
    "        z1 = np.dot(self.w1, x_train)\n",
    "        a1 = 1/(1 + np.exp(-z1)) # sigmoid activation\n",
    "        z2 = np.dot(self.w2, a1)\n",
    "        a2 = 1/(1 + np.exp(-z2)) # sigmoid activation\n",
    "        z3 = np.dot(self.w3, a2)\n",
    "        a3 = np.exp(z3)/sum(np.exp(z3)) # softmax activation\n",
    "        \n",
    "        # we need to remember all values for backpropagation\n",
    "        self.fwdpass = [x_train, z1, a1, z2, a2, z3, a3]\n",
    "        \n",
    "        return a3\n",
    "    \n",
    "    \n",
    "    def backprop(self, y, y_hat):\n",
    "        # restore values from foward pass\n",
    "        a0, z1, a1, z2, a2, z3, a3 = self.fwdpass\n",
    "        \n",
    "        # Calculate W3 update\n",
    "        exps = np.exp(z3 - z3.max())\n",
    "        softmax_derivative = exps / np.sum(exps, axis=0) * (1 - exps / np.sum(exps, axis=0))\n",
    "        error = 2 * (y_hat - y) / y_hat.shape[0] * softmax_derivative\n",
    "        gradient_w3 = np.outer(error, a2)\n",
    "\n",
    "        # Calculate W2 update\n",
    "        sigmoid_derivative = (np.exp(-z2))/((np.exp(-z2)+1)**2)\n",
    "        error = np.dot(self.w3.T, error) * sigmoid_derivative\n",
    "        gradient_w2 = np.outer(error, a1)\n",
    "\n",
    "        # Calculate W1 update\n",
    "        sigmoid_derivative = (np.exp(-z1))/((np.exp(-z1)+1)**2)\n",
    "        error = np.dot(self.w2.T, error) * sigmoid_derivative\n",
    "        gradient_w1 = np.outer(error, a0)\n",
    "\n",
    "        return [gradient_w1, gradient_w2, gradient_w3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output of the last layer looks like this:\n",
      " [5.13892189e-02 4.31072252e-06 2.25095624e-08 4.20524030e-08\n",
      " 1.16018028e-09 3.04792788e-07 7.17666893e-05 1.95730962e-03\n",
      " 9.46575277e-01 1.74626318e-06]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test for task 1:\n",
    "dnn = DeepNeuralNetwork()\n",
    "\n",
    "# the network outputs a probability for every neuron in the last layer\n",
    "y_hat = dnn.forward_pass(X_train[0])\n",
    "print(\"The output of the last layer looks like this:\\n\", y_hat)\n",
    "\n",
    "# to check if the network works correctly, check if the following condition is True\n",
    "abs(y_hat[8] - 0.946) < 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.13892189e-02 4.31072252e-06 2.25095624e-08 4.20524030e-08\n",
      " 1.16018028e-09 3.04792788e-07 7.17666893e-05 1.95730962e-03\n",
      " 9.46575277e-01 1.74626318e-06]\n"
     ]
    }
   ],
   "source": [
    "print(dnn.forward_pass(X_train[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Implement  the training procedure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now start training the network by implementing the training procedure. We train the network for 10 epochs as shown in the code below.\n",
    "In each epoch we go over every data point `x` in `X_train` and:\n",
    "1. Calculate a forward pass on `x` as `y_hat`\n",
    "2. Calculate the gradients for the weight in w1, w2 and w3 using the `backprop` function of the network\n",
    "3. Update the weights w1, w2 and w3 of the network by moving into the negative direction of the gradient multiplied with the `learning_rate`\n",
    "4. Bonus: Calculate the cross-entropy-loss after each epoch and plot it in relation to the epochs.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Time: 17.8s, Loss: 161410\n",
      "Epoch: 2, Time: 33.9s, Loss: 102991\n",
      "Epoch: 3, Time: 51.8s, Loss: 80930\n",
      "Epoch: 4, Time: 70.4s, Loss: 66489\n",
      "Epoch: 5, Time: 87.1s, Loss: 57511\n",
      "Epoch: 6, Time: 102.9s, Loss: 51712\n",
      "Epoch: 7, Time: 119.2s, Loss: 47585\n",
      "Epoch: 8, Time: 135.9s, Loss: 44429\n",
      "Epoch: 9, Time: 154.0s, Loss: 41907\n",
      "Epoch: 10, Time: 171.6s, Loss: 39830\n"
     ]
    }
   ],
   "source": [
    "dnn = DeepNeuralNetwork()\n",
    "\n",
    "no_epochs = 10\n",
    "learning_rate = 0.01\n",
    "\n",
    "start_time = time.time()\n",
    "losses = []\n",
    "for iteration in range(no_epochs):\n",
    "    loss = 0\n",
    "    for x,y in zip(X_train, y_train):\n",
    "        y_hat = dnn.forward_pass(x)\n",
    "        gradients = dnn.backprop(y, y_hat)\n",
    "        \n",
    "        loss += -np.log(np.dot(y, y_hat))\n",
    "        \n",
    "        # one step stochastic gradient descent\n",
    "        dnn.w1 -= learning_rate * gradients[0]\n",
    "        dnn.w2 -= learning_rate * gradients[1]\n",
    "        dnn.w3 -= learning_rate * gradients[2]\n",
    "\n",
    "    print(f'Epoch: {iteration+1}, Time: {time.time() - start_time:.1f}s, Loss: {loss:.0f}')\n",
    "    losses.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'loss')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "plt.plot(range(0, no_epochs), losses)\n",
    "plt.xlabel('number of epochs')\n",
    "plt.ylabel('loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3: Predict on the test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the network is trained, we can use it to predict on the test data.\n",
    "\n",
    "__Task__: \n",
    "- Iterate over the test data and use the trained network the predict on every test data point.\n",
    "- Identify the index of the neuron which returned the highest probability.\n",
    "- Compare this value to the true label in the test data.\n",
    "- Compute the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7936190476190477\n"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "for x, y in zip(X_test, y_test):\n",
    "    output = dnn.forward_pass(x)\n",
    "    pred = np.argmax(output)\n",
    "    predictions.append(pred == np.argmax(y))\n",
    "accuracy = np.mean(predictions)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus Task:\n",
    "- Remove the first hidden layer. Train the network and check the performance on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "\n",
    "class DeepNeuralNetworkSmall():\n",
    "    def __init__(self):\n",
    "        \n",
    "        # initialize weights randomly\n",
    "        np.random.seed(0)\n",
    "        self.w1 = np.random.randn(64, 784)\n",
    "        self.w2 = np.random.randn(10, 64)\n",
    "\n",
    "    def forward_pass(self, x_train):\n",
    "        z1 = np.dot(self.w1, x_train)\n",
    "        a1 = 1/(1 + np.exp(-z1)) # sigmoid activation\n",
    "        z2 = np.dot(self.w2, a1)\n",
    "        a2 = np.exp(z2)/sum(np.exp(z2)) # softmax activation\n",
    "        \n",
    "        # we need to remember all values for backpropagation\n",
    "        self.fwdpass = [x_train, z1, a1, z2, a2]\n",
    "        \n",
    "        return a2\n",
    "    \n",
    "    \n",
    "    def backprop(self, y, y_hat):\n",
    "        # restore values from foward pass\n",
    "        a0, z1, a1, z2, a2 = self.fwdpass\n",
    "        \n",
    "        # Calculate W2 update\n",
    "        exps = np.exp(z2 - z2.max())\n",
    "        softmax_derivative = exps / np.sum(exps, axis=0) * (1 - exps / np.sum(exps, axis=0))\n",
    "        error = 2 * (y_hat - y) / y_hat.shape[0] * softmax_derivative\n",
    "        gradient_w2 = np.outer(error, a1)\n",
    "\n",
    "        # Calculate W1 update\n",
    "        sigmoid_derivative = (np.exp(-z1))/((np.exp(-z1)+1)**2)\n",
    "        error = np.dot(self.w2.T, error) * sigmoid_derivative\n",
    "        gradient_w1 = np.outer(error, a0)\n",
    "\n",
    "        return [gradient_w1, gradient_w2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Time: 9.8s, Loss: 237385\n",
      "Epoch: 2, Time: 19.6s, Loss: 130831\n",
      "Epoch: 3, Time: 29.6s, Loss: 99504\n",
      "Epoch: 4, Time: 40.1s, Loss: 79784\n",
      "Epoch: 5, Time: 50.1s, Loss: 66653\n",
      "Epoch: 6, Time: 59.9s, Loss: 57996\n",
      "Epoch: 7, Time: 69.9s, Loss: 52095\n",
      "Epoch: 8, Time: 79.7s, Loss: 47924\n",
      "Epoch: 9, Time: 89.7s, Loss: 44824\n",
      "Epoch: 10, Time: 99.9s, Loss: 42405\n"
     ]
    }
   ],
   "source": [
    "dnn = DeepNeuralNetworkSmall()\n",
    "\n",
    "no_epochs = 10\n",
    "learning_rate = 0.01\n",
    "\n",
    "start_time = time.time()\n",
    "losses = []\n",
    "for iteration in range(no_epochs):\n",
    "    loss = 0\n",
    "    for x,y in zip(X_train, y_train):\n",
    "        y_hat = dnn.forward_pass(x)\n",
    "        gradients = dnn.backprop(y, y_hat)\n",
    "        \n",
    "        loss += -np.log(np.dot(y, y_hat))\n",
    "        \n",
    "        # one step stochastic gradient descent\n",
    "        dnn.w1 -= learning_rate * gradients[0]\n",
    "        dnn.w2 -= learning_rate * gradients[1]\n",
    "\n",
    "    print(f'Epoch: {iteration+1}, Time: {time.time() - start_time:.1f}s, Loss: {loss:.0f}')\n",
    "    losses.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7852380952380953\n"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "for x, y in zip(X_test, y_test):\n",
    "    output = dnn.forward_pass(x)\n",
    "    pred = np.argmax(output)\n",
    "    predictions.append(pred == np.argmax(y))\n",
    "accuracy = np.mean(predictions)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
